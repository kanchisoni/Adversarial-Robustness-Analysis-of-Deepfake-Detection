{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMo69g2aNnlqxTTpOzWFsF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanchisoni/Adversarial-Robustness-Analysis-of-Deepfake-Detection/blob/main/Adversarial_Robustness_Analysis_of_Deepfake_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPyvShj2jHKo",
        "outputId": "99d306b6-8b5c-4926-accd-7be2dbd93824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/prithivsakthiur/deepfake-vs-real-60k?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22.4G/22.4G [17:32<00:00, 22.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/prithivsakthiur/deepfake-vs-real-60k/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"prithivsakthiur/deepfake-vs-real-60k\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_path = path\n",
        "print(os.listdir(data_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBDhVUSejPvE",
        "outputId": "8ca23fed-db0a-4231-c983-5b0c6212338d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['deepfake-vs-real-60k']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n"
      ],
      "metadata": {
        "id": "uOJYZrGyjUGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = os.path.join(path, os.listdir(path)[0])\n",
        "print(\"DATA PATH:\", data_path)\n",
        "print(\"INSIDE:\", os.listdir(data_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxX0OAwHjYzW",
        "outputId": "c50c41dc-ba15-43af-eb72-5ad319d7ae65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA PATH: /root/.cache/kagglehub/datasets/prithivsakthiur/deepfake-vs-real-60k/versions/1/deepfake-vs-real-60k\n",
            "INSIDE: ['Real', 'Fake']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_path = path # Ensure data_path is correct\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(299,299),\n",
        "    batch_size=16,\n",
        "    label_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(299,299),\n",
        "    batch_size=16,\n",
        "    label_mode=\"categorical\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzRsDnAVjdU1",
        "outputId": "50e0a3c8-fc0f-463b-9aee-c4c7f55f5c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 57071 files belonging to 2 classes.\n",
            "Using 45657 files for training.\n",
            "Found 57071 files belonging to 2 classes.\n",
            "Using 11414 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(lambda x,y: (preprocess_input(x), y))\n",
        "val_ds   = val_ds.map(lambda x,y: (preprocess_input(x), y))\n"
      ],
      "metadata": {
        "id": "3C4QQ2majgfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(299,299,3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "out = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(base_model.input, out)\n"
      ],
      "metadata": {
        "id": "hAqdPFeOjjLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "caCaeiWXjl6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, epochs=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIiBnQeZjoYb",
        "outputId": "6eb2db5a-5305-4354-852c-4d42bbec393b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m2854/2854\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1393s\u001b[0m 458ms/step - accuracy: 0.9894 - loss: 0.0343 - val_accuracy: 0.9976 - val_loss: 0.0084\n",
            "Epoch 2/3\n",
            "\u001b[1m2854/2854\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1226s\u001b[0m 429ms/step - accuracy: 0.9975 - loss: 0.0090 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
            "Epoch 3/3\n",
            "\u001b[1m2854/2854\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1263s\u001b[0m 442ms/step - accuracy: 0.9978 - loss: 0.0073 - val_accuracy: 0.9987 - val_loss: 0.0051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(val_ds)\n",
        "print(f\"Baseline Validation Accuracy: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "UMljn40kHJT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b35044-1c91-4375-f6ad-75d86bacc38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 168ms/step - accuracy: 0.9986 - loss: 0.0050\n",
            "Baseline Validation Accuracy: 99.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "def fgsm_attack(images, labels, model, epsilon=0.01):\n",
        "    images = tf.cast(images, tf.float32)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(images)\n",
        "        preds = model(images)\n",
        "        loss = loss_object(labels, preds)\n",
        "\n",
        "    gradient = tape.gradient(loss, images)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    adv_images = images + epsilon * signed_grad\n",
        "    adv_images = tf.clip_by_value(adv_images, -1, 1)  # because of preprocess_input\n",
        "\n",
        "    return adv_images\n"
      ],
      "metadata": {
        "id": "tQxfpXdzpRQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_imgs = []\n",
        "adv_lbls = []\n",
        "\n",
        "for imgs, lbls in val_ds.take(20):  # small portion is enough\n",
        "    adv = fgsm_attack(imgs, lbls, model)\n",
        "    adv_imgs.append(adv)\n",
        "    adv_lbls.append(lbls)\n",
        "\n",
        "adv_imgs = tf.concat(adv_imgs, axis=0)\n",
        "adv_lbls = tf.concat(adv_lbls, axis=0)\n"
      ],
      "metadata": {
        "id": "p5YOSYespT9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, adv_acc = model.evaluate(adv_imgs, adv_lbls, verbose=0)\n",
        "print(f\"Accuracy on FGSM adversarial images: {adv_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lfGYsmWpVLp",
        "outputId": "28c27f0c-2316-428b-98aa-6629e3347f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on FGSM adversarial images: 77.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def blur_defense(images):\n",
        "    out = []\n",
        "    for img in images:\n",
        "        img_np = img.numpy()\n",
        "        img_np = cv2.GaussianBlur(img_np, (5,5), 0)\n",
        "        out.append(img_np)\n",
        "    return tf.convert_to_tensor(out)\n",
        "\n",
        "blurred = blur_defense(adv_imgs)\n",
        "loss, blur_acc = model.evaluate(blurred, adv_lbls, verbose=0)\n",
        "print(f\"Accuracy after Blur Defense: {blur_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2OSQW6dpY62",
        "outputId": "70406c90-84ab-43c3-dd7f-4e04ddc6286a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after Blur Defense: 96.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "\n",
        "def wavelet_defense(images):\n",
        "    processed = []\n",
        "    for img in images:\n",
        "        img = img.numpy()\n",
        "        coeffs = pywt.dwt2(img[:,:,0], 'haar')\n",
        "        cA, (cH, cV, cD) = coeffs\n",
        "        rec = pywt.idwt2((cA, (None, None, None)), 'haar')\n",
        "        rec = np.stack([rec]*3, axis=-1)\n",
        "        processed.append(rec)\n",
        "    return tf.convert_to_tensor(processed)\n",
        "\n",
        "wave_imgs = wavelet_defense(adv_imgs)\n",
        "loss, wave_acc = model.evaluate(wave_imgs, adv_lbls, verbose=0)\n",
        "print(f\"Accuracy after Wavelet Defense: {wave_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud5t1B0cpaPg",
        "outputId": "8b3d3ce6-4e2e-4f54-c6fb-8c3eebcedb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after Wavelet Defense: 93.75%\n"
          ]
        }
      ]
    }
  ]
}